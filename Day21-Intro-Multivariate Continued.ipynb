{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 21 - Multivariate Stats (continued)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last week we talked about the basics of multilinear regression. Here are some last minute assumptions and items you should think about in order to fine tune your regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                charges   R-squared:                       0.120\n",
      "Model:                            OLS   Adj. R-squared:                  0.118\n",
      "Method:                 Least Squares   F-statistic:                     60.69\n",
      "Date:                Sun, 07 Apr 2024   Prob (F-statistic):           8.80e-37\n",
      "Time:                        22:56:45   Log-Likelihood:                -14392.\n",
      "No. Observations:                1338   AIC:                         2.879e+04\n",
      "Df Residuals:                    1334   BIC:                         2.881e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "age          239.9945     22.289     10.767      0.000     196.269     283.720\n",
      "bmi          332.0834     51.310      6.472      0.000     231.425     432.741\n",
      "children     542.8647    258.241      2.102      0.036      36.261    1049.468\n",
      "const      -6916.2433   1757.480     -3.935      0.000   -1.04e+04   -3468.518\n",
      "==============================================================================\n",
      "Omnibus:                      325.395   Durbin-Watson:                   2.012\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              603.372\n",
      "Skew:                           1.520   Prob(JB):                    9.54e-132\n",
      "Kurtosis:                       4.255   Cond. No.                         290.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "df = pd.read_csv('data/insurance.csv')\n",
    "\n",
    "y = df['charges']                    \n",
    "X = df.select_dtypes(np.number).assign(const=1)\n",
    "X = X.drop(columns=['charges'])\n",
    "X.head()\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multicollinearity\n",
    "\n",
    "Multicollinearity refers to the intercorrelation among features. MLR assumes that there is minimal to no correlation among features. High correlations among features will bias the estimates. When high multicollinearity exists, predictions will be very sensitive to (i.e., highly fluctuate with) very small variations in the features. The condition number (Cond. No.) is one example of a test of multicollinearity that is included in the StatsModels MLR results. Smaller numbers are better here. Generally speaking, values < 1 are ideal. But that assumes that the data are standardizedâ€”which ours was not (yet).\n",
    "\n",
    "Regardless, Condition number is not the best test of multicollinearity available today. Variance inflation factor (VIF) is a much better indicator of multicollinearity. It is basically a measure of how much each of the X features overlap each other. We calculate VIF by ignoring the label and treating each X feature as the label in a model based on all remaining X features. The R2 of each model is used in a simple equation (1 / (1 - R2)) to calculate VIF. \n",
    "\n",
    "VIF scores below 3 (great), 5 (good), 10 (okay) have each been argued to indicate acceptable levels of multicollinearity depending on the strictness desired. O'Brien (2007) provides a helpful discussion of which level is best. However, if your goal is to model a prediction where parsimony and limiting over-fitting is desired, I would recommend using 3 as the cutoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>1.013816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>1.012152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>children</th>\n",
       "      <td>1.001874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               VIF\n",
       "age       1.013816\n",
       "bmi       1.012152\n",
       "children  1.001874"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The VIF score for each X feature and print the scores in a DataFrame\n",
    "\n",
    "df_vif = pd.DataFrame(columns=['VIF'])\n",
    "\n",
    "# Loop through the X features only to generate VIF score for each\n",
    "for col in X.drop(columns=['const']):\n",
    "    y = X[col] # Each X feature takes a turn being the y\n",
    "    # All remaining X features are used to predict that y\n",
    "    vifX = X.drop(columns=[col]).assign(const=1)\n",
    "    \n",
    "    r_squared = sm.OLS(y, vifX).fit().rsquared # Record the R squared from the model\n",
    "    \n",
    "    if r_squared < 1: # Prevent division by zero runtime error\n",
    "      vif = 1/(1 - r_squared) \n",
    "    else:\n",
    "      vif = 100\n",
    "    df_vif.loc[col] = vif\n",
    "\n",
    "# Print out the list of VIF scores sorted from highest (worst) to lowest (best)\n",
    "df_vif.sort_values(by=['VIF'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "\n",
    "Feature scaling is a method used to adjust the range of features values to the same scale. Although some algorithms (e.g., MLR) do not depend on feature scaling to produce results, other algorithms will produce biased results if features have different ranges. Another reason to scale is that many algorithms will converge faster (e.g., find the minimum sum of squared residuals) if all features are on the same scale, including MLR, logistic regression, nearest neighbors, neural networks, support vector machines, principal components analysis, and linear discriminant analysis. You may not know what all of those mean yet, but just know that scaling is a good idea.\n",
    "\n",
    "It is important to note that scaling does not change the shape or distribution of the data, only the range of the values. What is the implication of that? It means that problems with normalcy (e.g., skewness, kurtosis, heteroscedasticity) will not change after scaling. Those issues are resolved prior to scaling with mathematical adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scikit-learn package has four built-in forms of scaling: StandardScaler (z-score), MinMaxScaler, RobustScaler, and Normalizer. However, the most common are the first two. We will use MinMax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.461022</td>\n",
       "      <td>0.395572</td>\n",
       "      <td>0.218984</td>\n",
       "      <td>0.193916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.305434</td>\n",
       "      <td>0.164062</td>\n",
       "      <td>0.241099</td>\n",
       "      <td>0.193301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.278080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.388485</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.131849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.504002</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.247700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age          bmi     children      charges\n",
       "count  1338.000000  1338.000000  1338.000000  1338.000000\n",
       "mean      0.461022     0.395572     0.218984     0.193916\n",
       "std       0.305434     0.164062     0.241099     0.193301\n",
       "min       0.000000     0.000000     0.000000     0.000000\n",
       "25%       0.195652     0.278080     0.000000     0.057757\n",
       "50%       0.456522     0.388485     0.200000     0.131849\n",
       "75%       0.717391     0.504002     0.400000     0.247700\n",
       "max       1.000000     1.000000     1.000000     1.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Min-Max Normalization\n",
    "#preproccessing. (Other methods)\n",
    "\n",
    "df2 = df.select_dtypes(np.number)\n",
    "\n",
    "df_minmax = pd.DataFrame(preprocessing.MinMaxScaler().fit_transform(df2), columns=df2.columns)\n",
    "\n",
    "df_minmax.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39.207025</td>\n",
       "      <td>30.663397</td>\n",
       "      <td>1.094918</td>\n",
       "      <td>13270.422265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.049960</td>\n",
       "      <td>6.098187</td>\n",
       "      <td>1.205493</td>\n",
       "      <td>12110.011237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>15.960000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1121.873900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>26.296250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4740.287150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>30.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9382.033000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>34.693750</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>16639.912515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>53.130000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>63770.428010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age          bmi     children       charges\n",
       "count  1338.000000  1338.000000  1338.000000   1338.000000\n",
       "mean     39.207025    30.663397     1.094918  13270.422265\n",
       "std      14.049960     6.098187     1.205493  12110.011237\n",
       "min      18.000000    15.960000     0.000000   1121.873900\n",
       "25%      27.000000    26.296250     0.000000   4740.287150\n",
       "50%      39.000000    30.400000     1.000000   9382.033000\n",
       "75%      51.000000    34.693750     2.000000  16639.912515\n",
       "max      64.000000    53.130000     5.000000  63770.428010"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the MLR with the new standardized variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                charges   R-squared:                       0.120\n",
      "Model:                            OLS   Adj. R-squared:                  0.118\n",
      "Method:                 Least Squares   F-statistic:                     60.69\n",
      "Date:                Sun, 07 Apr 2024   Prob (F-statistic):           8.80e-37\n",
      "Time:                        23:37:38   Log-Likelihood:                 386.57\n",
      "No. Observations:                1338   AIC:                            -765.1\n",
      "Df Residuals:                    1334   BIC:                            -744.3\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "age            0.1762      0.016     10.767      0.000       0.144       0.208\n",
      "bmi            0.1970      0.030      6.472      0.000       0.137       0.257\n",
      "children       0.0433      0.021      2.102      0.036       0.003       0.084\n",
      "const          0.0252      0.015      1.689      0.091      -0.004       0.055\n",
      "==============================================================================\n",
      "Omnibus:                      325.395   Durbin-Watson:                   2.012\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              603.372\n",
      "Skew:                           1.520   Prob(JB):                    9.54e-132\n",
      "Kurtosis:                       4.255   Cond. No.                         7.89\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "y = df_minmax['charges']                    \n",
    "X = df_minmax.assign(const=1)\n",
    "X = X.drop(columns=['charges'])\n",
    "\n",
    "model2 = sm.OLS(y, X)\n",
    "results2 = model2.fit()\n",
    "\n",
    "print(results2.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
